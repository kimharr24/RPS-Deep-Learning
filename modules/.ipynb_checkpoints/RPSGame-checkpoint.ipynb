{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from cvzone.SelfiSegmentationModule import SelfiSegmentation\n",
    "from MakeDataset import *\n",
    "from DataLoaders import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def findKeyFromValue(hashMap, value):\n",
    "    \"\"\"\n",
    "    Retrieves the key from a hash map, assuming all values are also unique.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    hashMap: the hash map to retrieve the key from.\n",
    "    value: the value to find in the hash map.\n",
    "    \n",
    "    Returns the key corresponding to the value.\n",
    "    \"\"\"\n",
    "    \n",
    "    key_list = list(hashMap.keys())\n",
    "    val_list = list(hashMap.values())\n",
    "    \n",
    "    position = val_list.index(value)\n",
    "    \n",
    "    return key_list[position]\n",
    "    \n",
    "def conformImgToModel(img):\n",
    "    \"\"\"\n",
    "    Converts (300 x 300 x 3) array to CNN expectation of (1 x 3 x 300 x 300) input tensor\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    img: The image to be transformed\n",
    "    \n",
    "    Returns a (1 x 3 x 300 x 300) image tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fix the color channel from BGR to RGB since the model was trained on RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Remove the background since the model was trained on images with backgrounds removed\n",
    "    img = removeBackground(img)\n",
    "    \n",
    "    # Model expects tensor input, convert from numpy to tensor\n",
    "    img = torch.tensor(img) \n",
    "    \n",
    "    # Tensor is (300 x 300 x 3) because of the numpy array, switch to (3 x 300 x 300)\n",
    "    img = img.permute(2, 0, 1)\n",
    "    \n",
    "    # Model expects a batch size dimension, simply add a dummy dimension\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def makePrediction(img, model):\n",
    "    \"\"\"\n",
    "    Trained CNN makes a prediction on the current image.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    img: a numpy array of the current image (300 x 300)\n",
    "    model: the pre-trained PyTorch CNN created in network-trainer.ipynb\n",
    "    \n",
    "    Returns a string representing the model's class prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    img = conformImgToModel(img)\n",
    "    \n",
    "    # Dummy transform to get label_mappings\n",
    "    train_transform = defineDataTransform(\"train\")\n",
    "    label_mappings = createDataLoader(\"data/rps-train\", train_transform, get_label_mappings = True)\n",
    "    \n",
    "    _, prediction_as_num = torch.max(softmax(model(img.float())), dim = 1)\n",
    "       \n",
    "    prediction = findKeyFromValue(label_mappings, prediction_as_num)\n",
    "   \n",
    "    return prediction\n",
    "    \n",
    "def executeGame(model):\n",
    "    \"\"\"\n",
    "    Main function to play rock, paper, scissors.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    model: the pre-trained PyTorch CNN created in network-trainer.ipynb\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the webcam object\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Visual settings for webcam display\n",
    "    coordinates, fontScale, thickness, font, color = (5, 18), 0.45, 2, cv2.FONT_HERSHEY_SIMPLEX, (0, 255, 0)\n",
    "    \n",
    "    while True:\n",
    "        success, img = camera.read()\n",
    "        img = rescaleImg(img)\n",
    "        \n",
    "        #Pass the current frame into the model to retrieve a class prediction and probability\n",
    "        prediction = makePrediction(img, model)\n",
    "        \n",
    "        img = cv2.putText(img, f\"Prediction: {prediction}\", coordinates, font, fontScale, color, thickness)\n",
    "        cv2.imshow(\"Recording Window\", img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
